# Fully Connected Neural Networks


## Learning Goals

Introduce fully connected neural networks

Learn how to compute the number of parameters of your model

## FCNN


A network where every neuron in one layer connects to every neuron in the next layer
- Each output depends on ALL input features


### FCNN Diagram explained

On the left of the diagram, input ball is a feature

Every line connecting two balls is a weight

A neuron in a hidden or output layer  has:
- 1 incoming line per input
- One bias

ziâ€‹=wi1â€‹x1â€‹+wi2â€‹x2â€‹+wi3â€‹x3â€‹+bi

A bias is not drawn but is:
- An extra input that is always + 1
- With it's own weight

A layer of neurons is:
- output vector=Ïƒ(Wâ‹…input vector+B)
- All lines together = weight matrix W
- All biases = bias vector B

On the most right, the balls are the output

Depending on the tasks:
- Regression: Each output ball is a predicted value, often no activation at the end
- Classification: Each output ball is a class score, softmax activation turns them into probabilities


Balls are neurons, lines are weights, each neuron sums its incoming weighted lines, adds a bias, applies an activation, and passes the result forward.


### Single layer FCNN

No hidden layers just input and outputs

S=Ïƒ(WXiTâ€‹+B)


Where:

ð‘‹= one sample

ð‘Š= weights

ðµ= bias

ðœŽ= activation


### Multi layer FCNN

Input -> Hidden layer -> Output

Each layer has its own weights, bias, and activation

Each Layer:
1. S(1)=Ïƒ1â€‹(W(1)XiTâ€‹+B(1))
2. S(2)=Ïƒ2â€‹(W(2)S(1)+B(2))

* Function Composite -> Output of one layer becomes the input to the next

### Parameter Counting

(M + 1) x C = P

(Inputs + Bias) * Outputs = Parameters

Parameters tell you:

- Model capacity

- Risk of overfitting

- Memory requirements

- Computational cost


More parameters:

- More expressive

- More data needed

- Higher overfitting risk



### Summary


FCNNs alternate linear operations and non-linear activations

Each neuron computes a weighted sum + bias, then applies an activation

Softmax converts outputs into probabilities for classification

Parameter count per layer is:

(inputs+1)Ã—outputs

Multi-layer networks are built by stacking these layers